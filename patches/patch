diff --git a/include/linux/swap.h b/include/linux/swap.h
index b2ae6f50b..3e2f1de10 100644
--- a/include/linux/swap.h
+++ b/include/linux/swap.h
@@ -375,6 +375,26 @@ extern unsigned long reclaim_pages(struct list_head *page_list);
 extern int add_page_for_swap(struct page *page, struct list_head *pagelist);
 extern struct page *get_page_from_vaddr(struct mm_struct *mm,
 					unsigned long vaddr);
+
+// [page cache]新增
+
+// 限制page cache比例
+extern unsigned long page_cache_limit_ratio;
+// 限制page cache数量
+extern unsigned long page_cache_limit_mbytes;
+// 设置比重
+extern unsigned int page_cache_reclaim_weight;
+// 设置定时器时间
+extern int page_cache_reclaim_s;
+// 是否开启该功能
+extern int page_cache_reclaim_enable;
+// 判断page cache是否超过上限
+extern unsigned long page_cache_over_limit(void);
+// page cache回收函数
+extern unsigned long shrink_page_cache(gfp_t mask);
+// TODO: proc节点处理函数
+
+
 #ifdef CONFIG_NUMA
 extern int node_reclaim_mode;
 extern int sysctl_min_unmapped_ratio;
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index e2729e82b..b1e4614a0 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -2665,6 +2665,37 @@ static struct ctl_table kern_table[] = {
 };
 
 static struct ctl_table vm_table[] = {
+//		[page cache] 新增
+	{
+		.procname	= "page_cache_reclaim_s",
+		.data		= &page_cache_reclaim_s,
+		.maxlen		= sizeof(page_cache_reclaim_s),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= &four,
+		// TODO: 最大值最小值
+	},
+	{
+		.procname	= "page_cache_reclaim_weight",
+		.data		= &page_cache_reclaim_weight,
+		.maxlen		= sizeof(page_cache_reclaim_weight),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= &four,
+		// TODO: 最大值最小值
+	},
+	{
+		.procname	= "page_cache_reclaim_enable",
+		.data		= &page_cache_reclaim_enable,
+		.maxlen		= sizeof(page_cache_reclaim_enable),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= &four,
+		// TODO: 最大值最小值
+	},
 	{
 		.procname	= "overcommit_memory",
 		.data		= &sysctl_overcommit_memory,
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index c72ecf5c9..730f00c98 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -8873,3 +8873,18 @@ bool take_page_off_buddy(struct page *page)
 	return ret;
 }
 #endif
+
+// [page cache] 新增
+unsigned long page_cache_over_limit(void)
+{
+	// TODO: 后续确认匿名页部分如何处理
+	unsigned long lru_file, limit;
+
+	limit = page_cache_limit_mbytes * ((1024 * 1024UL) /PAGE_SIZE);
+	lru_file = global_node_page_state(NR_ACTIVE_FILE)
+		+ global_node_page_state(NR_INACTIVE_FILE);
+	if (lru_file > limit)
+		return lru_file - limit;
+	
+	return 0;
+}
\ No newline at end of file
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 7760d50e6..260fd9306 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -167,6 +167,16 @@ struct scan_control {
 #define prefetchw_prev_lru_page(_page, _base, _field) do { } while (0)
 #endif
 
+
+// [page cache] 新增
+unsigned long page_cache_limit_ratio;
+unsigned long page_cache_limit_mbytes;
+unsigned int page_cache_reclaim_weight;
+int page_cache_reclaim_s;
+int page_cache_reclaim_enable;
+
+
+
 /*
  * From 0 .. 200.  Higher means more swappy.
  */
@@ -3561,6 +3571,11 @@ static int balance_pgdat(pg_data_t *pgdat, int order, int highest_zoneidx)
 
 	count_vm_event(PAGEOUTRUN);
 
+	
+	// [page cache] 新增
+	if (page_cache_limit_mbytes && page_cache_over_limit())
+		shrink_page_cache(GFP_KERNEL);
+
 	/*
 	 * Account for the reclaim boost. Note that the zone boost is left in
 	 * place so that parallel allocations that are near the watermark will
@@ -4028,6 +4043,57 @@ unsigned long shrink_all_memory(unsigned long nr_to_reclaim)
 }
 #endif /* CONFIG_HIBERNATION */
 
+
+// [page cache] 新增
+static unsigned long __shrink_page_cache(gfp_t mask)
+{
+	printk(KERN_EMERG "__shrink_page_cache");
+	struct scan_control sc = {
+		.gfp_mask = current_gfp_context(mask),
+		.reclaim_idx = gfp_zone(mask),
+		.may_writepage = !laptop_mode,
+		.nr_to_reclaim = SWAP_CLUSTER_MAX *
+				 (unsigned long)page_cache_reclaim_weight,
+		.may_unmap = 1,
+		.may_swap = 1,
+		.order = 0,
+		.priority = DEF_PRIORITY,
+		.target_mem_cgroup = NULL,
+		.nodemask = NULL,
+	};
+
+	struct zonelist *zonelist = node_zonelist(numa_node_id(), mask);
+
+	return do_try_to_free_pages(zonelist, &sc);
+}
+
+unsigned long shrink_page_cache(gfp_t mask)
+{
+	printk(KERN_EMERG "shrink_page_cache");
+	unsigned long nr_pages;
+
+	// TODO: highmem zone
+	nr_pages = __shrink_page_cache(mask);
+
+	return nr_pages;
+
+
+}
+
+static void shrink_page_cache_init(void)
+{	
+	printk(KERN_EMERG "shink page cache init");	
+	page_cache_limit_ratio = 5;
+	page_cache_limit_mbytes = 10;
+	page_cache_reclaim_s = 6;
+	page_cache_reclaim_weight = 10;
+
+	page_cache_reclaim_enable = 1;
+
+	// TODO 启动内核Timer定时器
+}
+
+
 /*
  * This kswapd start function will be called by init and node-hot-add.
  * On node-hot-add, kswapd will moved to proper cpus if cpus are hot-added.
@@ -4067,11 +4133,15 @@ void kswapd_stop(int nid)
 
 static int __init kswapd_init(void)
 {
+
+	printk(KERN_EMERG "kswapd_init\n");
 	int nid;
 
 	swap_setup();
 	for_each_node_state(nid, N_MEMORY)
  		kswapd_run(nid);
+	// [page cache] 新增
+	shrink_page_cache_init();
 	return 0;
 }
 
